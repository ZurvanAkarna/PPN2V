{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23a4357",
   "metadata": {},
   "source": [
    "# üß¨ N2V + PN2V Pipeline - Complete Denoising with Uncertainty\n",
    "\n",
    "**Two-Stage Pipeline:**\n",
    "1. **Stage 1: N2V Optimized** - Fast denoising with optimized configuration\n",
    "2. **Stage 2: PN2V Bootstrap** - Uses N2V output to build noise model ‚Üí uncertainty maps\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 1: N2V Configuration\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| Network Depth | 3 | Optimal U-Net depth |\n",
    "| Network Width | 4 | Starting channels (narrow network) |\n",
    "| Mask Patch Size | 7√ó7 | Larger blind spots |\n",
    "| Mask Value | Zero | Replace with 0 (not neighbor) |\n",
    "\n",
    "## Stage 2: PN2V Bootstrap\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| Noise Model | GMM | Gaussian Mixture Model (3 components) |\n",
    "| Bootstrap Source | N2V output | Signal estimate from Stage 1 |\n",
    "| Output | MMSE + Uncertainty | Probabilistic denoising |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c768a6",
   "metadata": {},
   "source": [
    "## üìÅ Section 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "\n",
    "# Define paths - SEPARATE DIRECTORIES for N2V and PN2V results\n",
    "DRIVE_PROJECT_PATH = '/content/drive/MyDrive/PPN2V'\n",
    "\n",
    "# ========== DATA PATH - YOUR DATASET_01 FOLDER ==========\n",
    "DRIVE_DATA_PATH = '/content/drive/MyDrive/PPN2V/DATASET_01'\n",
    "\n",
    "# Stage 1: N2V results\n",
    "N2V_RESULTS_PATH = '/content/drive/MyDrive/PPN2V/results/DATASET_01/n2v_optimized'\n",
    "\n",
    "# Stage 2: PN2V results  \n",
    "PN2V_RESULTS_PATH = '/content/drive/MyDrive/PPN2V/results/DATASET_01/pn2v_bootstrap'\n",
    "\n",
    "# Final comparison\n",
    "COMPARISON_PATH = '/content/drive/MyDrive/PPN2V/results/DATASET_01/comparison'\n",
    "\n",
    "# Create all directories\n",
    "for path in [N2V_RESULTS_PATH, PN2V_RESULTS_PATH, COMPARISON_PATH]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Drive mounted\")\n",
    "print(f\"\\nüìÅ Data Path:     {DRIVE_DATA_PATH}\")\n",
    "print(f\"üìÅ Output Directories:\")\n",
    "print(f\"  N2V Results:    {N2V_RESULTS_PATH}\")\n",
    "print(f\"  PN2V Results:   {PN2V_RESULTS_PATH}\")\n",
    "print(f\"  Comparison:     {COMPARISON_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616724bc",
   "metadata": {},
   "source": [
    "## üì• Section 2: Clone Repository & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ba617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Clone or update repository\n",
    "REPO_PATH = '/content/PPN2V'\n",
    "GITHUB_REPO = 'https://github.com/ZurvanAkarna/PPN2V.git'\n",
    "\n",
    "if os.path.exists(REPO_PATH):\n",
    "    print(\"Repository exists, pulling latest changes...\")\n",
    "    os.chdir(REPO_PATH)\n",
    "    subprocess.run(['git', 'pull'], check=True)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    subprocess.run(['git', 'clone', GITHUB_REPO, REPO_PATH], check=True)\n",
    "    os.chdir(REPO_PATH)\n",
    "\n",
    "# Install the package\n",
    "print(\"\\nInstalling PPN2V package...\")\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.', '-q'], check=True)\n",
    "\n",
    "# Install additional dependencies\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', 'tifffile', 'scikit-image', '-q'], check=True)\n",
    "\n",
    "print(\"\\n‚úì Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9496a",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìã CONFIGURATION - EDIT THESE PARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Data settings\n",
    "    'data_name': 'DATASET_01',\n",
    "    # YOUR EXACT FILENAME:\n",
    "    'data_file': 'noisy_image_jitter_skips_0__0_3_flags_0__0_4_Gaussian_0.6.tif',\n",
    "    \n",
    "    # ========== STAGE 1: N2V Optimized ==========\n",
    "    # Network architecture\n",
    "    'net_depth': 3,                     # U-Net depth\n",
    "    'net_width': 4,                     # Starting channels\n",
    "    \n",
    "    # Masking parameters\n",
    "    'mask_patch_size': 7,               # 7x7 blind spot patches\n",
    "    'mask_ratio': 0.10,                 # 10% pixels masked per iteration\n",
    "    'val_mask_ratio': 0.02,             # 2% static validation mask\n",
    "    \n",
    "    # Training parameters\n",
    "    'n2v_max_epochs': 100,              # N2V maximum training epochs\n",
    "    'n2v_patience': 20,                 # N2V early stopping patience\n",
    "    'learning_rate': 0.001,             # Adam learning rate\n",
    "    \n",
    "    # ========== STAGE 2: PN2V Bootstrap ==========\n",
    "    # GMM Noise Model\n",
    "    'n_gaussian': 3,                    # Number of Gaussian components\n",
    "    'n_coeff': 2,                       # Polynomial coefficients (2 = linear)\n",
    "    'gmm_epochs': 2000,                 # GMM training epochs\n",
    "    'gmm_batch_size': 250000,           # GMM batch size\n",
    "    \n",
    "    # PN2V Network\n",
    "    'pn2v_num_samples': 1000,           # Number of output samples\n",
    "    'pn2v_max_epochs': 200,             # PN2V training epochs\n",
    "    'pn2v_patience': 15,                # PN2V early stopping patience\n",
    "    'pn2v_steps_per_epoch': 50,         # Steps per epoch\n",
    "    'pn2v_batch_size': 4,               # Batch size\n",
    "    'pn2v_patch_size': 100,             # Patch size for training\n",
    "}\n",
    "\n",
    "# Print configuration\n",
    "print(\"=\"*60)\n",
    "print(\"COMPLETE PIPELINE CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÑ Data file: {CONFIG['data_file']}\")\n",
    "print(\"\\nüìå STAGE 1: N2V Optimized\")\n",
    "for key in ['net_depth', 'net_width', 'mask_patch_size', 'n2v_max_epochs', 'n2v_patience']:\n",
    "    print(f\"  {key}: {CONFIG[key]}\")\n",
    "print(\"\\nüìå STAGE 2: PN2V Bootstrap\")\n",
    "for key in ['n_gaussian', 'n_coeff', 'pn2v_num_samples', 'pn2v_max_epochs']:\n",
    "    print(f\"  {key}: {CONFIG[key]}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62297797",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Section 4: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d28854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load noisy image\n",
    "data_path = os.path.join(DRIVE_DATA_PATH, CONFIG['data_file'])\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"‚ö†Ô∏è  File not found: {data_path}\")\n",
    "    print(f\"\\nPlease upload your noisy image to:\")\n",
    "    print(f\"  {DRIVE_DATA_PATH}/{CONFIG['data_file']}\")\n",
    "    print(f\"\\nOr modify CONFIG['data_file'] to match your filename.\")\n",
    "else:\n",
    "    noisy_image = tifffile.imread(data_path).astype(np.float32)\n",
    "    \n",
    "    # Handle 3D stack - use first slice or choose\n",
    "    if noisy_image.ndim == 3:\n",
    "        print(f\"Loaded 3D stack: {noisy_image.shape}\")\n",
    "        print(f\"Using first slice for training...\")\n",
    "        noisy_image = noisy_image[0]  # Use first slice\n",
    "    \n",
    "    print(f\"\\n‚úì Loaded image: {noisy_image.shape}\")\n",
    "    print(f\"  Min: {noisy_image.min():.2f}\")\n",
    "    print(f\"  Max: {noisy_image.max():.2f}\")\n",
    "    print(f\"  Mean: {noisy_image.mean():.2f}\")\n",
    "    print(f\"  Std: {noisy_image.std():.2f}\")\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(noisy_image, cmap='magma')\n",
    "    plt.colorbar()\n",
    "    plt.title('Noisy Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67557eeb",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Section 5: Create Model & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "# Add source to path (required for Colab)\n",
    "sys.path.insert(0, '/content/PPN2V/src')\n",
    "\n",
    "from ppn2v.n2v import N2VUNet, N2VTrainer, create_n2v_model\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Create model with optimized configuration\n",
    "model = create_n2v_model(\n",
    "    device=device,\n",
    "    depth=CONFIG['net_depth'],\n",
    "    start_channels=CONFIG['net_width']\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = N2VTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    mask_ratio=CONFIG['mask_ratio'],\n",
    "    mask_patch_size=CONFIG['mask_patch_size'],\n",
    "    val_mask_ratio=CONFIG['val_mask_ratio']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model and trainer created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48500b86",
   "metadata": {},
   "source": [
    "## üöÄ Section 6: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996421aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_name = f\"n2v_{CONFIG['data_name']}_d{CONFIG['net_depth']}_w{CONFIG['net_width']}\"\n",
    "\n",
    "train_history, val_history = trainer.train(\n",
    "    image=noisy_image,\n",
    "    max_epochs=CONFIG['n2v_max_epochs'],\n",
    "    patience=CONFIG['n2v_patience'],\n",
    "    save_dir=N2V_RESULTS_PATH,\n",
    "    model_name=model_name,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_history, label='Training Loss', color='blue')\n",
    "plt.plot(val_history, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('N2V Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_history, label='Training Loss', color='blue')\n",
    "plt.plot(val_history, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss (log)')\n",
    "plt.yscale('log')\n",
    "plt.title('N2V Training Progress (Log Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(N2V_RESULTS_PATH, f'training_curves_{model_name}.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì N2V training curves saved to: {N2V_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf0e8c",
   "metadata": {},
   "source": [
    "## üîÆ Section 7: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppn2v.n2v import load_model\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(N2V_RESULTS_PATH, f'best_{model_name}.pth')\n",
    "best_model = load_model(best_model_path, device)\n",
    "\n",
    "# Create new trainer with loaded model for prediction\n",
    "predictor = N2VTrainer(best_model, device)\n",
    "predictor.model.mean = trainer.model.mean\n",
    "predictor.model.std = trainer.model.std\n",
    "\n",
    "# Predict\n",
    "n2v_denoised = predictor.predict(noisy_image)\n",
    "\n",
    "print(f\"‚úì N2V Prediction complete!\")\n",
    "print(f\"  Denoised image shape: {n2v_denoised.shape}\")\n",
    "print(f\"  Min: {n2v_denoised.min():.2f}\")\n",
    "print(f\"  Max: {n2v_denoised.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078f4c5",
   "metadata": {},
   "source": [
    "## üìä Section 8: N2V Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N2V Side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Noisy input\n",
    "im0 = axes[0].imshow(noisy_image, cmap='magma')\n",
    "axes[0].set_title('Noisy Input', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046)\n",
    "\n",
    "# N2V Denoised output\n",
    "im1 = axes[1].imshow(n2v_denoised, cmap='magma')\n",
    "axes[1].set_title('N2V Denoised', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046)\n",
    "\n",
    "# Difference (noise removed)\n",
    "n2v_difference = noisy_image - n2v_denoised\n",
    "vmax = np.abs(n2v_difference).max()\n",
    "im2 = axes[2].imshow(n2v_difference, cmap='RdBu_r', vmin=-vmax, vmax=vmax)\n",
    "axes[2].set_title('N2V Removed Noise', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046)\n",
    "\n",
    "plt.suptitle('STAGE 1: N2V Results', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(N2V_RESULTS_PATH, f'n2v_comparison_{model_name}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c372a",
   "metadata": {},
   "source": [
    "## üíæ Section 9: Save N2V Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebce8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save N2V denoised image\n",
    "n2v_output_filename = f\"n2v_denoised_{CONFIG['data_name']}.tif\"\n",
    "n2v_output_path = os.path.join(N2V_RESULTS_PATH, n2v_output_filename)\n",
    "tifffile.imwrite(n2v_output_path, n2v_denoised.astype(np.float32))\n",
    "print(f\"‚úì N2V denoised image saved: {n2v_output_path}\")\n",
    "\n",
    "# Save N2V difference image\n",
    "n2v_diff_filename = f\"n2v_noise_removed_{CONFIG['data_name']}.tif\"\n",
    "n2v_diff_path = os.path.join(N2V_RESULTS_PATH, n2v_diff_filename)\n",
    "tifffile.imwrite(n2v_diff_path, n2v_difference.astype(np.float32))\n",
    "print(f\"‚úì N2V noise map saved: {n2v_diff_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ STAGE 1 COMPLETE: N2V Results Saved\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Results directory: {N2V_RESULTS_PATH}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde34d1",
   "metadata": {},
   "source": [
    "---\n",
    "# üî¨ STAGE 2: PN2V Bootstrap\n",
    "\n",
    "Now we use the N2V prediction as the \"signal estimate\" to build a noise model, then train PN2V for probabilistic denoising with uncertainty quantification.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Section 10: Create GMM Noise Model (Bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba25884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppn2v.pn2v import gaussianMixtureNoiseModel\n",
    "\n",
    "# Bootstrap: Use N2V prediction as signal estimate\n",
    "# observation = noisy image, signal = N2V denoised\n",
    "observation = noisy_image.flatten()\n",
    "signal = n2v_denoised.flatten()\n",
    "\n",
    "# Determine signal range for noise model\n",
    "min_signal = float(np.percentile(signal, 0.5))\n",
    "max_signal = float(np.percentile(signal, 99.5))\n",
    "\n",
    "print(\"Creating GMM Noise Model (Bootstrap from N2V)...\")\n",
    "print(f\"  Signal range: [{min_signal:.2f}, {max_signal:.2f}]\")\n",
    "print(f\"  Gaussians: {CONFIG['n_gaussian']}\")\n",
    "print(f\"  Coefficients: {CONFIG['n_coeff']}\")\n",
    "\n",
    "# Create and train GMM noise model\n",
    "gmm_noise_model = gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(\n",
    "    min_signal=min_signal,\n",
    "    max_signal=max_signal,\n",
    "    path=PN2V_RESULTS_PATH,\n",
    "    weight=None,\n",
    "    n_gaussian=CONFIG['n_gaussian'],\n",
    "    n_coeff=CONFIG['n_coeff'],\n",
    "    device=device,\n",
    "    min_sigma=50  # Prevents degenerate solutions\n",
    ")\n",
    "\n",
    "# Train the noise model\n",
    "gmm_noise_model.train(\n",
    "    signal=signal,\n",
    "    observation=observation,\n",
    "    batchSize=CONFIG['gmm_batch_size'],\n",
    "    n_epochs=CONFIG['gmm_epochs'],\n",
    "    learning_rate=0.1,\n",
    "    name=f\"GMMNoiseModel_{CONFIG['data_name']}_bootstrap\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì GMM Noise Model trained and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b804798f",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Section 11: Train PN2V Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppn2v.unet.model import UNet\n",
    "from ppn2v.pn2v import training, utils\n",
    "\n",
    "# Create PN2V U-Net (outputs multiple samples for probabilistic inference)\n",
    "pn2v_net = UNet(\n",
    "    n_channels=CONFIG['pn2v_num_samples'],  # Output channels = number of samples\n",
    "    n_depth=5,\n",
    "    n_dim_start=64,\n",
    "    merge_mode='add'\n",
    ")\n",
    "pn2v_net = pn2v_net.to(device)\n",
    "\n",
    "# Prepare training data (expand dims for training format)\n",
    "train_data = noisy_image[np.newaxis, :, :]  # Shape: (1, H, W)\n",
    "val_data = noisy_image[np.newaxis, :, :]    # Use same image for validation\n",
    "\n",
    "# Compute normalization parameters\n",
    "all_data = np.concatenate([train_data, val_data], axis=0)\n",
    "pn2v_net.mean = np.mean(all_data)\n",
    "pn2v_net.std = np.std(all_data)\n",
    "\n",
    "print(f\"PN2V Network created:\")\n",
    "print(f\"  Output samples: {CONFIG['pn2v_num_samples']}\")\n",
    "print(f\"  Data mean: {pn2v_net.mean:.2f}\")\n",
    "print(f\"  Data std: {pn2v_net.std:.2f}\")\n",
    "\n",
    "# Train PN2V\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING PN2V NETWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pn2v_net_postfix = f\"pn2v_{CONFIG['data_name']}_bootstrap\"\n",
    "\n",
    "trainHist, valHist = training.trainNetwork(\n",
    "    net=pn2v_net,\n",
    "    trainData=train_data,\n",
    "    valData=val_data,\n",
    "    postfix=pn2v_net_postfix,\n",
    "    directory=PN2V_RESULTS_PATH,\n",
    "    noiseModel=gmm_noise_model,\n",
    "    device=device,\n",
    "    numOfEpochs=CONFIG['pn2v_max_epochs'],\n",
    "    stepsPerEpoch=CONFIG['pn2v_steps_per_epoch'],\n",
    "    batchSize=CONFIG['pn2v_batch_size'],\n",
    "    patchSize=CONFIG['pn2v_patch_size'],\n",
    "    learningRate=0.0001,\n",
    "    earlyStopPatience=CONFIG['pn2v_patience']\n",
    ")\n",
    "\n",
    "# Plot PN2V training curves\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(trainHist, label='Training Loss', color='blue')\n",
    "plt.plot(valHist, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('PN2V Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(PN2V_RESULTS_PATH, f'pn2v_training_curves_{pn2v_net_postfix}.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì PN2V training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291020b",
   "metadata": {},
   "source": [
    "## üîÆ Section 12: PN2V Prediction with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppn2v.pn2v import prediction\n",
    "\n",
    "# Load best PN2V model\n",
    "pn2v_net = torch.load(os.path.join(PN2V_RESULTS_PATH, f'best_{pn2v_net_postfix}.net'))\n",
    "pn2v_net = pn2v_net.to(device)\n",
    "pn2v_net.eval()\n",
    "\n",
    "# Prepare image for prediction\n",
    "noisy_for_pred = np.squeeze(noisy_image).astype(np.float32)\n",
    "\n",
    "print(\"Running PN2V prediction...\")\n",
    "print(\"  This generates MMSE estimate and prior mean\")\n",
    "\n",
    "# PN2V Prediction with tiled processing for large images\n",
    "pn2v_prior_mean, pn2v_mmse = prediction.tiledPredict(\n",
    "    im=noisy_for_pred,\n",
    "    net=pn2v_net,\n",
    "    noiseModel=gmm_noise_model,\n",
    "    device=device,\n",
    "    ps=256,       # Tile size\n",
    "    overlap=48    # Overlap between tiles\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì PN2V Prediction complete!\")\n",
    "print(f\"  Prior Mean shape: {pn2v_prior_mean.shape}\")\n",
    "print(f\"  MMSE shape: {pn2v_mmse.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8d9bb",
   "metadata": {},
   "source": [
    "## üìà Section 13: Compute Uncertainty Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute uncertainty from the network's sample outputs\n",
    "# Run network to get all samples\n",
    "noisy_norm = (noisy_for_pred - pn2v_net.mean) / pn2v_net.std\n",
    "\n",
    "# Pad for U-Net\n",
    "H, W = noisy_norm.shape\n",
    "pad_h = (32 - H % 32) % 32\n",
    "pad_w = (32 - W % 32) % 32\n",
    "\n",
    "if pad_h > 0 or pad_w > 0:\n",
    "    noisy_padded = np.pad(noisy_norm, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "else:\n",
    "    noisy_padded = noisy_norm\n",
    "\n",
    "# Get samples from network\n",
    "input_tensor = torch.from_numpy(noisy_padded).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = pn2v_net(input_tensor) * 10.0  # Output scaling factor\n",
    "    \n",
    "# Denormalize samples\n",
    "samples_np = samples.cpu().numpy()[0]  # Shape: (num_samples, H, W)\n",
    "samples_denorm = samples_np * pn2v_net.std + pn2v_net.mean\n",
    "\n",
    "# Crop if padded\n",
    "if pad_h > 0 or pad_w > 0:\n",
    "    samples_denorm = samples_denorm[:, :H, :W]\n",
    "\n",
    "# Compute uncertainty metrics\n",
    "# 1. Standard deviation across samples (epistemic uncertainty)\n",
    "std_map = np.std(samples_denorm, axis=0)\n",
    "\n",
    "# 2. Coefficient of variation (relative uncertainty)\n",
    "mean_map = np.mean(samples_denorm, axis=0)\n",
    "cv_map = std_map / (np.abs(mean_map) + 1e-8)\n",
    "\n",
    "# 3. Confidence interval width (95%)\n",
    "percentile_2_5 = np.percentile(samples_denorm, 2.5, axis=0)\n",
    "percentile_97_5 = np.percentile(samples_denorm, 97.5, axis=0)\n",
    "ci_width = percentile_97_5 - percentile_2_5\n",
    "\n",
    "print(\"‚úì Uncertainty maps computed!\")\n",
    "print(f\"  Standard deviation range: [{std_map.min():.2f}, {std_map.max():.2f}]\")\n",
    "print(f\"  95% CI width range: [{ci_width.min():.2f}, {ci_width.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760ed51",
   "metadata": {},
   "source": [
    "## üé® Section 14: Visualize Uncertainty Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize uncertainty maps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Row 1: Denoised results\n",
    "im0 = axes[0, 0].imshow(noisy_image, cmap='magma')\n",
    "axes[0, 0].set_title('Noisy Input', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0, 0], fraction=0.046)\n",
    "\n",
    "im1 = axes[0, 1].imshow(pn2v_prior_mean, cmap='magma')\n",
    "axes[0, 1].set_title('PN2V Prior Mean', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "im2 = axes[0, 2].imshow(pn2v_mmse, cmap='magma')\n",
    "axes[0, 2].set_title('PN2V MMSE (Best Estimate)', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046)\n",
    "\n",
    "# Row 2: Uncertainty maps\n",
    "im3 = axes[1, 0].imshow(std_map, cmap='hot')\n",
    "axes[1, 0].set_title('Uncertainty: Std Deviation', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im3, ax=axes[1, 0], fraction=0.046)\n",
    "\n",
    "im4 = axes[1, 1].imshow(cv_map, cmap='hot', vmin=0, vmax=np.percentile(cv_map, 99))\n",
    "axes[1, 1].set_title('Uncertainty: Coeff. of Variation', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im4, ax=axes[1, 1], fraction=0.046)\n",
    "\n",
    "im5 = axes[1, 2].imshow(ci_width, cmap='hot')\n",
    "axes[1, 2].set_title('Uncertainty: 95% CI Width', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "plt.colorbar(im5, ax=axes[1, 2], fraction=0.046)\n",
    "\n",
    "plt.suptitle('PN2V Results with Uncertainty Quantification', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PN2V_RESULTS_PATH, f'pn2v_uncertainty_{CONFIG[\"data_name\"]}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f5222",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Section 15: Compare N2V vs PN2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac71219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison of N2V vs PN2V\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Row 1: Full images\n",
    "im0 = axes[0, 0].imshow(noisy_image, cmap='magma')\n",
    "axes[0, 0].set_title('Noisy Input', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0, 0], fraction=0.046)\n",
    "\n",
    "im1 = axes[0, 1].imshow(n2v_denoised, cmap='magma')\n",
    "axes[0, 1].set_title('N2V Optimized', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "im2 = axes[0, 2].imshow(pn2v_mmse, cmap='magma')\n",
    "axes[0, 2].set_title('PN2V MMSE', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046)\n",
    "\n",
    "# Difference between methods\n",
    "method_diff = n2v_denoised - pn2v_mmse\n",
    "vmax_diff = np.abs(method_diff).max()\n",
    "im3 = axes[0, 3].imshow(method_diff, cmap='RdBu_r', vmin=-vmax_diff, vmax=vmax_diff)\n",
    "axes[0, 3].set_title('N2V - PN2V Difference', fontsize=12)\n",
    "axes[0, 3].axis('off')\n",
    "plt.colorbar(im3, ax=axes[0, 3], fraction=0.046)\n",
    "\n",
    "# Row 2: Zoomed comparison\n",
    "h, w = noisy_image.shape\n",
    "crop_size = min(256, h//2, w//2)\n",
    "cy, cx = h//2, w//2\n",
    "y1, y2 = cy - crop_size//2, cy + crop_size//2\n",
    "x1, x2 = cx - crop_size//2, cx + crop_size//2\n",
    "\n",
    "axes[1, 0].imshow(noisy_image[y1:y2, x1:x2], cmap='magma')\n",
    "axes[1, 0].set_title('Noisy (Zoomed)', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(n2v_denoised[y1:y2, x1:x2], cmap='magma')\n",
    "axes[1, 1].set_title('N2V (Zoomed)', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(pn2v_mmse[y1:y2, x1:x2], cmap='magma')\n",
    "axes[1, 2].set_title('PN2V MMSE (Zoomed)', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(std_map[y1:y2, x1:x2], cmap='hot')\n",
    "axes[1, 3].set_title('Uncertainty (Zoomed)', fontsize=12)\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.suptitle('N2V vs PN2V Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(COMPARISON_PATH, f'n2v_vs_pn2v_{CONFIG[\"data_name\"]}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print comparison statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nN2V Optimized:\")\n",
    "print(f\"  Mean: {n2v_denoised.mean():.2f}\")\n",
    "print(f\"  Std: {n2v_denoised.std():.2f}\")\n",
    "print(f\"\\nPN2V MMSE:\")\n",
    "print(f\"  Mean: {pn2v_mmse.mean():.2f}\")\n",
    "print(f\"  Std: {pn2v_mmse.std():.2f}\")\n",
    "print(f\"\\nMethod Difference (N2V - PN2V):\")\n",
    "print(f\"  Mean absolute diff: {np.abs(method_diff).mean():.4f}\")\n",
    "print(f\"  Max absolute diff: {np.abs(method_diff).max():.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a4306",
   "metadata": {},
   "source": [
    "## üíæ Section 16: Save All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aecd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PN2V results\n",
    "data_name = CONFIG['data_name']\n",
    "\n",
    "# PN2V denoised images\n",
    "tifffile.imwrite(os.path.join(PN2V_RESULTS_PATH, f'pn2v_prior_mean_{data_name}.tif'), \n",
    "                 pn2v_prior_mean.astype(np.float32))\n",
    "tifffile.imwrite(os.path.join(PN2V_RESULTS_PATH, f'pn2v_mmse_{data_name}.tif'), \n",
    "                 pn2v_mmse.astype(np.float32))\n",
    "\n",
    "# Uncertainty maps\n",
    "tifffile.imwrite(os.path.join(PN2V_RESULTS_PATH, f'uncertainty_std_{data_name}.tif'), \n",
    "                 std_map.astype(np.float32))\n",
    "tifffile.imwrite(os.path.join(PN2V_RESULTS_PATH, f'uncertainty_cv_{data_name}.tif'), \n",
    "                 cv_map.astype(np.float32))\n",
    "tifffile.imwrite(os.path.join(PN2V_RESULTS_PATH, f'uncertainty_ci95_{data_name}.tif'), \n",
    "                 ci_width.astype(np.float32))\n",
    "\n",
    "# Comparison results\n",
    "tifffile.imwrite(os.path.join(COMPARISON_PATH, f'n2v_denoised_{data_name}.tif'), \n",
    "                 n2v_denoised.astype(np.float32))\n",
    "tifffile.imwrite(os.path.join(COMPARISON_PATH, f'pn2v_mmse_{data_name}.tif'), \n",
    "                 pn2v_mmse.astype(np.float32))\n",
    "tifffile.imwrite(os.path.join(COMPARISON_PATH, f'method_difference_{data_name}.tif'), \n",
    "                 method_diff.astype(np.float32))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ ALL RESULTS SAVED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÅ N2V Results: {N2V_RESULTS_PATH}\")\n",
    "for f in os.listdir(N2V_RESULTS_PATH):\n",
    "    size_kb = os.path.getsize(os.path.join(N2V_RESULTS_PATH, f)) / 1024\n",
    "    print(f\"   üìÑ {f} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nüìÅ PN2V Results: {PN2V_RESULTS_PATH}\")\n",
    "for f in os.listdir(PN2V_RESULTS_PATH):\n",
    "    size_kb = os.path.getsize(os.path.join(PN2V_RESULTS_PATH, f)) / 1024\n",
    "    print(f\"   üìÑ {f} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nüìÅ Comparison: {COMPARISON_PATH}\")\n",
    "for f in os.listdir(COMPARISON_PATH):\n",
    "    size_kb = os.path.getsize(os.path.join(COMPARISON_PATH, f)) / 1024\n",
    "    print(f\"   üìÑ {f} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23049cc5",
   "metadata": {},
   "source": [
    "## üì§ Section 17: Commit to GitHub (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dccdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you want to push changes to GitHub\n",
    "# You'll need to authenticate with your GitHub token\n",
    "\n",
    "RUN_GIT_PUSH = False  # Change to True to enable\n",
    "\n",
    "if RUN_GIT_PUSH:\n",
    "    from getpass import getpass\n",
    "    \n",
    "    # Get credentials\n",
    "    GITHUB_USERNAME = input(\"GitHub username: \")\n",
    "    GITHUB_TOKEN = getpass(\"GitHub token (hidden): \")\n",
    "    \n",
    "    os.chdir(REPO_PATH)\n",
    "    \n",
    "    # Configure git\n",
    "    subprocess.run(['git', 'config', 'user.email', f'{GITHUB_USERNAME}@users.noreply.github.com'])\n",
    "    subprocess.run(['git', 'config', 'user.name', GITHUB_USERNAME])\n",
    "    \n",
    "    # Set remote with authentication\n",
    "    auth_url = f'https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/ZurvanAkarna/PPN2V.git'\n",
    "    subprocess.run(['git', 'remote', 'set-url', 'origin', auth_url])\n",
    "    \n",
    "    # Check for changes\n",
    "    result = subprocess.run(['git', 'status', '--porcelain'], capture_output=True, text=True)\n",
    "    if result.stdout.strip():\n",
    "        print(\"Changes detected:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Add and commit\n",
    "        subprocess.run(['git', 'add', '-A'])\n",
    "        commit_msg = f\"N2V+PN2V pipeline: {CONFIG['data_name']}\"\n",
    "        subprocess.run(['git', 'commit', '-m', commit_msg])\n",
    "        subprocess.run(['git', 'push', 'origin', 'main'])\n",
    "        print(\"\\n‚úì Changes pushed to GitHub!\")\n",
    "    else:\n",
    "        print(\"No changes to commit.\")\n",
    "else:\n",
    "    print(\"Git push disabled. Set RUN_GIT_PUSH = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcee600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Pipeline Complete!\n",
    "\n",
    "You have successfully run the complete N2V ‚Üí PN2V pipeline:\n",
    "\n",
    "### Stage 1: N2V Optimized ‚úÖ\n",
    "- Fast denoising with optimized blind-spot configuration\n",
    "- Results in: `Google Drive/MyDrive/PPN2V/results/n2v_optimized/`\n",
    "\n",
    "### Stage 2: PN2V Bootstrap ‚úÖ\n",
    "- Used N2V output as signal estimate for noise model\n",
    "- Trained GMM noise model + PN2V network\n",
    "- Results in: `Google Drive/MyDrive/PPN2V/results/pn2v_bootstrap/`\n",
    "\n",
    "### Comparison & Uncertainty ‚úÖ\n",
    "- Side-by-side N2V vs PN2V comparison\n",
    "- Uncertainty maps (Std Dev, Coeff. of Variation, 95% CI)\n",
    "- Results in: `Google Drive/MyDrive/PPN2V/results/comparison/`\n",
    "\n",
    "---\n",
    "\n",
    "### Output Files Summary:\n",
    "\n",
    "| Directory | File | Description |\n",
    "|-----------|------|-------------|\n",
    "| `n2v_optimized/` | `n2v_denoised_*.tif` | N2V denoised image |\n",
    "| `n2v_optimized/` | `best_*.pth` | Best N2V model |\n",
    "| `pn2v_bootstrap/` | `pn2v_mmse_*.tif` | PN2V MMSE estimate |\n",
    "| `pn2v_bootstrap/` | `uncertainty_std_*.tif` | Standard deviation map |\n",
    "| `pn2v_bootstrap/` | `uncertainty_cv_*.tif` | Coefficient of variation map |\n",
    "| `pn2v_bootstrap/` | `uncertainty_ci95_*.tif` | 95% confidence interval width |\n",
    "| `comparison/` | `n2v_vs_pn2v_*.png` | Visual comparison |\n",
    "| `comparison/` | `method_difference_*.tif` | Difference between methods |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
