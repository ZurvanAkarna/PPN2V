{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4109b190",
   "metadata": {},
   "source": [
    "# üî¨ PPN2V Denoising Pipeline - Google Colab\n",
    "\n",
    "**Parametric Probabilistic Noise2Void** for DATASET_01\n",
    "\n",
    "This notebook runs the complete denoising pipeline:\n",
    "1. Mount Google Drive & Clone Repository\n",
    "2. Install Dependencies\n",
    "3. Load Data from Drive\n",
    "4. Create Noise Models (Histogram + GMM)\n",
    "5. Train PN2V Network\n",
    "6. Generate Predictions + Uncertainty Maps\n",
    "7. Save Results to Drive\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è FIRST: Enable GPU Runtime!**\n",
    "- Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU` ‚Üí `Save`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f94a5",
   "metadata": {},
   "source": [
    "## üìÅ Section 1: Mount Google Drive\n",
    "\n",
    "This connects your Google Drive so we can read data and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify your data exists\n",
    "!ls \"/content/drive/MyDrive/ppn2v_data/DATASET_01/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c927e08",
   "metadata": {},
   "source": [
    "## üì¶ Section 2: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122cc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old clone if exists\n",
    "!rm -rf /content/PPN2V\n",
    "\n",
    "# Clone your repository from GitHub\n",
    "!git clone https://github.com/ZurvanAkarna/PPN2V.git /content/PPN2V\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned!\")\n",
    "!ls /content/PPN2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a20c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to repo directory\n",
    "%cd /content/PPN2V\n",
    "\n",
    "# Install the PPN2V package\n",
    "!pip install -e . -q\n",
    "!pip install tifffile scikit-image -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports and check GPU\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Add source to path\n",
    "sys.path.insert(0, '/content/PPN2V/src')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"‚úÖ GPU is ready!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PPN2V modules\n",
    "from ppn2v.pn2v import gaussianMixtureNoiseModel, histNoiseModel, training, prediction, utils\n",
    "from ppn2v.unet.model import UNet\n",
    "from tifffile import imread, imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ PPN2V modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ac90b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 3: Configuration\n",
    "\n",
    "**Edit these settings if needed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ PATHS ============\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "DATA_DIR = f\"{DRIVE_ROOT}/ppn2v_data/DATASET_01\"\n",
    "MODELS_DIR = f\"{DRIVE_ROOT}/ppn2v_models/DATASET_01\"\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# ============ DATASET ============\n",
    "dataName = 'dataset01'\n",
    "target_noise_level = 0.7  # Change if using different noise level\n",
    "\n",
    "# ============ TRAINING CONFIG ============\n",
    "# Adjust these for speed vs quality tradeoff\n",
    "CONFIG = {\n",
    "    'n_gaussian': 3,          # GMM components\n",
    "    'n_coeff': 2,             # Polynomial coefficients\n",
    "    'n_samples': 800,         # Network output samples\n",
    "    'depth': 3,               # U-Net depth\n",
    "    'numOfEpochs': 200,       # Max training epochs\n",
    "    'stepsPerEpoch': 50,      # Steps per epoch\n",
    "    'batchSize': 4,           # Batch size\n",
    "    'learningRate': 1e-3,     # Learning rate\n",
    "    'earlyStopPatience': 15,  # Stop if no improvement for N epochs (0=disable)\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"üìä Dataset: {dataName}\")\n",
    "print(f\"üìä Noise level: œÉ={target_noise_level}\")\n",
    "print(f\"üìä Max epochs: {CONFIG['numOfEpochs']} (early stop patience: {CONFIG['earlyStopPatience']})\")\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b155ec",
   "metadata": {},
   "source": [
    "## üì• Section 4: Load Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad80ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "clean_path = f\"{DATA_DIR}/clean_image.tif\"\n",
    "jittered_path = f\"{DATA_DIR}/jittered_image.tif\"\n",
    "noisy_path = f\"{DATA_DIR}/Noisy images/noisy_image_jitter_skips_0__0_3_flags_0__0_4_Gaussian_{target_noise_level}.tif\"\n",
    "\n",
    "# Check if files exist\n",
    "print(\"Checking files:\")\n",
    "print(f\"  Clean:    {'‚úÖ' if os.path.exists(clean_path) else '‚ùå'} {clean_path}\")\n",
    "print(f\"  Jittered: {'‚úÖ' if os.path.exists(jittered_path) else '‚ùå'} {jittered_path}\")\n",
    "print(f\"  Noisy:    {'‚úÖ' if os.path.exists(noisy_path) else '‚ùå'} {noisy_path}\")\n",
    "\n",
    "if not os.path.exists(clean_path):\n",
    "    print(\"\\n‚ùå ERROR: Data not found! Please upload to Google Drive:\")\n",
    "    print(f\"   {DATA_DIR}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6750153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "clean_image = imread(clean_path).astype(np.float32)\n",
    "jittered_image = imread(jittered_path).astype(np.float32)\n",
    "noisy_image = imread(noisy_path).astype(np.float32)\n",
    "\n",
    "print(\"‚úÖ Images loaded:\")\n",
    "print(f\"   Clean:    {clean_image.shape}, range [{clean_image.min():.2f}, {clean_image.max():.2f}]\")\n",
    "print(f\"   Jittered: {jittered_image.shape}, range [{jittered_image.min():.2f}, {jittered_image.max():.2f}]\")\n",
    "print(f\"   Noisy:    {noisy_image.shape}, range [{noisy_image.min():.2f}, {noisy_image.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0820f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(clean_image, cmap='gray')\n",
    "axes[0].set_title('Clean (Ground Truth)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(jittered_image, cmap='gray')\n",
    "axes[1].set_title('Jittered (Signal for Calibration)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(noisy_image, cmap='gray')\n",
    "axes[2].set_title(f'Noisy (œÉ={target_noise_level})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b35cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for pipeline\n",
    "WORK_DIR = '/content/PPN2V/examples/DATASET_01_code'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "%cd {WORK_DIR}\n",
    "\n",
    "# Save prepared data\n",
    "noisy_stack = noisy_image[np.newaxis, ...] if len(noisy_image.shape) == 2 else noisy_image\n",
    "\n",
    "imwrite(f'{dataName}_clean.tif', clean_image)\n",
    "imwrite(f'{dataName}_signal.tif', jittered_image)\n",
    "imwrite(f'{dataName}_noisy.tif', noisy_stack)\n",
    "\n",
    "print(f\"‚úÖ Data prepared in: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352bd39",
   "metadata": {},
   "source": [
    "## üìà Section 5: Create Noise Models\n",
    "\n",
    "We create two noise models:\n",
    "1. **Histogram** - Fast, lookup table\n",
    "2. **GMM** - Better quality, recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare signal/observation for calibration\n",
    "signal = jittered_image\n",
    "observation = noisy_image if len(noisy_image.shape) == 2 else noisy_image[0]\n",
    "\n",
    "signal_for_hist = signal[np.newaxis, ...]\n",
    "obs_for_hist = observation[np.newaxis, ...]\n",
    "\n",
    "# Determine intensity range\n",
    "all_values = np.concatenate([signal.flatten(), observation.flatten()])\n",
    "minVal = np.percentile(all_values, 0.5)\n",
    "maxVal = np.percentile(all_values, 99.5)\n",
    "bins = 256\n",
    "\n",
    "print(f\"üìä Intensity range: [{minVal:.2f}, {maxVal:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Histogram Noise Model\n",
    "print(\"üìà Creating Histogram Noise Model...\")\n",
    "\n",
    "nameHistNoiseModel = f'HistNoiseModel_{dataName}_calibration'\n",
    "histogram = histNoiseModel.createHistogram(bins, minVal, maxVal, obs_for_hist, signal_for_hist)\n",
    "np.save(nameHistNoiseModel + '.npy', histogram)\n",
    "\n",
    "print(f\"‚úÖ Saved: {nameHistNoiseModel}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GMM Noise Model (takes a few minutes)\n",
    "print(\"üìà Creating GMM Noise Model (this takes 2-5 minutes)...\")\n",
    "\n",
    "min_signal = np.percentile(signal, 0.5)\n",
    "max_signal = np.percentile(signal, 99.5)\n",
    "\n",
    "nameGMMNoiseModel = f\"GMMNoiseModel_{dataName}_{CONFIG['n_gaussian']}_{CONFIG['n_coeff']}_calibration\"\n",
    "\n",
    "gmmNoiseModel = gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(\n",
    "    min_signal=min_signal,\n",
    "    max_signal=max_signal,\n",
    "    path='./',\n",
    "    weight=None,\n",
    "    n_gaussian=CONFIG['n_gaussian'],\n",
    "    n_coeff=CONFIG['n_coeff'],\n",
    "    device=device,\n",
    "    min_sigma=50\n",
    ")\n",
    "\n",
    "gmmNoiseModel.train(\n",
    "    signal_for_hist,\n",
    "    obs_for_hist,\n",
    "    batchSize=250000,\n",
    "    n_epochs=2000,\n",
    "    learning_rate=0.1,\n",
    "    name=nameGMMNoiseModel,\n",
    "    lowerClip=0.5,\n",
    "    upperClip=99.5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Saved: {nameGMMNoiseModel}.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d501302",
   "metadata": {},
   "source": [
    "## üß† Section 6: Train PN2V Network\n",
    "\n",
    "This is the main training step. Time depends on epochs:\n",
    "- 50 epochs: ~15 min\n",
    "- 100 epochs: ~30 min\n",
    "- 200 epochs: ~60 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb87bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = imread(f'{dataName}_noisy.tif')\n",
    "print(f\"üìä Training data shape: {data.shape}\")\n",
    "\n",
    "# Select noise model (GMM recommended)\n",
    "nameNoiseModel = nameGMMNoiseModel\n",
    "print(f\"üìä Using noise model: {nameNoiseModel}\")\n",
    "\n",
    "# Load noise model\n",
    "params = np.load(nameNoiseModel + '.npz')\n",
    "noiseModel = gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(params=params, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network\n",
    "net = UNet(CONFIG['n_samples'], depth=CONFIG['depth'])\n",
    "\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"üìä Network parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN with Early Stopping!\n",
    "print(\"=\"*60)\n",
    "print(f\"üöÄ Starting training: max {CONFIG['numOfEpochs']} epochs\")\n",
    "print(f\"   Early stopping patience: {CONFIG['earlyStopPatience']} epochs\")\n",
    "print(f\"   (Training will stop if no improvement for {CONFIG['earlyStopPatience']} epochs)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainHist, valHist = training.trainNetwork(\n",
    "    net=net,\n",
    "    trainData=data.copy(),\n",
    "    valData=data.copy(),\n",
    "    postfix=nameNoiseModel,\n",
    "    directory='./',\n",
    "    noiseModel=noiseModel,\n",
    "    device=device,\n",
    "    numOfEpochs=CONFIG['numOfEpochs'],\n",
    "    stepsPerEpoch=CONFIG['stepsPerEpoch'],\n",
    "    virtualBatchSize=20,\n",
    "    batchSize=CONFIG['batchSize'],\n",
    "    learningRate=CONFIG['learningRate'],\n",
    "    earlyStopPatience=CONFIG['earlyStopPatience']  # NEW: Enable early stopping\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(f\"   Epochs trained: {len(trainHist)}\")\n",
    "print(f\"   Best val loss: {min(valHist):.6f} (epoch {np.argmin(valHist)+1})\")\n",
    "print(f\"   Final val loss: {valHist[-1]:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d73f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trainHist, label='Training Loss', alpha=0.7)\n",
    "plt.plot(valHist, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5040f33",
   "metadata": {},
   "source": [
    "## üîÆ Section 7: Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd73d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best trained network\n",
    "net = torch.load(f'best_{nameNoiseModel}.net', weights_only=False)\n",
    "print(f\"‚úÖ Loaded: best_{nameNoiseModel}.net\")\n",
    "\n",
    "# Load noise model\n",
    "params = np.load(nameNoiseModel + '.npz')\n",
    "noiseModel = gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(params=params, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "print(\"üîÆ Running prediction...\")\n",
    "\n",
    "noisy_for_pred = imread(f'{dataName}_noisy.tif')\n",
    "noisy_for_pred = np.squeeze(noisy_for_pred)\n",
    "\n",
    "from ppn2v.pn2v.prediction import predict\n",
    "means, mseEst = predict(noisy_for_pred, net, noiseModel, device, outScaling=10.0)\n",
    "\n",
    "print(f\"‚úÖ Prediction complete!\")\n",
    "print(f\"   Prior mean shape: {means.shape}\")\n",
    "print(f\"   MMSE estimate shape: {mseEst.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute uncertainty map\n",
    "print(\"üìä Computing uncertainty map...\")\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# Ensure 2D image\n",
    "noisy_2d = np.squeeze(noisy_for_pred)  # Remove any singleton dimensions\n",
    "print(f\"   Input shape: {noisy_2d.shape}\")\n",
    "\n",
    "img_normalized = (noisy_2d - net.mean) / net.std\n",
    "h, w = img_normalized.shape\n",
    "\n",
    "pad_h = (16 - h % 16) % 16\n",
    "pad_w = (16 - w % 16) % 16\n",
    "img_padded = np.pad(img_normalized, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_tensor = torch.from_numpy(img_padded[np.newaxis, np.newaxis, ...].astype(np.float32)).to(device)\n",
    "    output = net(img_tensor)\n",
    "    samples = output.cpu().numpy()[0] * 10.0 * net.std + net.mean\n",
    "    uncertainty_map = samples.std(axis=0)[:h, :w]\n",
    "\n",
    "print(f\"‚úÖ Uncertainty range: [{uncertainty_map.min():.4f}, {uncertainty_map.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d5e1c",
   "metadata": {},
   "source": [
    "## üìä Section 8: Calculate Metrics & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def normalize_01(img):\n",
    "    return (img - img.min()) / (img.max() - img.min() + 1e-10)\n",
    "\n",
    "clean_norm = normalize_01(clean_image)\n",
    "noisy_norm = normalize_01(noisy_for_pred)\n",
    "mmse_norm = normalize_01(np.squeeze(mseEst))\n",
    "\n",
    "psnr_noisy = psnr(clean_norm, noisy_norm, data_range=1.0)\n",
    "ssim_noisy = ssim(clean_norm, noisy_norm, data_range=1.0)\n",
    "psnr_mmse = psnr(clean_norm, mmse_norm, data_range=1.0)\n",
    "ssim_mmse = ssim(clean_norm, mmse_norm, data_range=1.0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä QUALITY METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Method':<25} {'PSNR (dB)':<12} {'SSIM':<10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Noisy (baseline)':<25} {psnr_noisy:<12.2f} {ssim_noisy:<10.4f}\")\n",
    "print(f\"{'PN2V (MMSE)':<25} {psnr_mmse:<12.2f} {ssim_mmse:<10.4f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Supervisor Benchmark':<25} {'28.48':<12} {'0.73':<10}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìà PSNR improvement: +{psnr_mmse - psnr_noisy:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Row 1: Images\n",
    "axes[0, 0].imshow(clean_image, cmap='gray')\n",
    "axes[0, 0].set_title('Ground Truth', fontsize=14)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(noisy_for_pred, cmap='gray')\n",
    "axes[0, 1].set_title(f'Noisy (PSNR: {psnr_noisy:.2f} dB)', fontsize=14)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(np.squeeze(mseEst), cmap='gray')\n",
    "axes[0, 2].set_title(f'PN2V Denoised (PSNR: {psnr_mmse:.2f} dB)', fontsize=14)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Row 2: Residuals and Uncertainty\n",
    "residual_noisy = noisy_for_pred - clean_image\n",
    "residual_denoised = np.squeeze(mseEst) - clean_image\n",
    "vmax = np.percentile(np.abs(residual_noisy), 99)\n",
    "\n",
    "axes[1, 0].imshow(residual_noisy, cmap='RdBu', vmin=-vmax, vmax=vmax)\n",
    "axes[1, 0].set_title('Residual (Noisy - Clean)', fontsize=14)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(residual_denoised, cmap='RdBu', vmin=-vmax, vmax=vmax)\n",
    "axes[1, 1].set_title('Residual (Denoised - Clean)', fontsize=14)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "im = axes[1, 2].imshow(uncertainty_map, cmap='hot')\n",
    "axes[1, 2].set_title('UNCERTAINTY MAP', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "plt.colorbar(im, ax=axes[1, 2], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e24604",
   "metadata": {},
   "source": [
    "## üíæ Section 9: Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Save denoised images locally first\n",
    "imwrite(f'{dataName}_denoised_mmse.tif', np.squeeze(mseEst).astype(np.float32))\n",
    "imwrite(f'{dataName}_denoised_prior_mean.tif', np.squeeze(means).astype(np.float32))\n",
    "imwrite(f'{dataName}_uncertainty_map.tif', uncertainty_map.astype(np.float32))\n",
    "\n",
    "# Files to copy to Drive\n",
    "files_to_save = [\n",
    "    f'{dataName}_denoised_mmse.tif',\n",
    "    f'{dataName}_denoised_prior_mean.tif',\n",
    "    f'{dataName}_uncertainty_map.tif',\n",
    "    f'{nameNoiseModel}.npz',\n",
    "    f'{nameHistNoiseModel}.npy',\n",
    "    f'best_{nameNoiseModel}.net',\n",
    "    f'last_{nameNoiseModel}.net',\n",
    "    'final_results.png',\n",
    "]\n",
    "\n",
    "print(f\"üíæ Saving to: {MODELS_DIR}\")\n",
    "for f in files_to_save:\n",
    "    if os.path.exists(f):\n",
    "        shutil.copy(f, MODELS_DIR)\n",
    "        print(f\"   ‚úÖ {f}\")\n",
    "\n",
    "# Save metrics report\n",
    "report = f\"\"\"PPN2V Denoising Results - DATASET_01\n",
    "{'='*50}\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Noise Level: œÉ={target_noise_level}\n",
    "\n",
    "QUALITY METRICS\n",
    "{'-'*50}\n",
    "Noisy (baseline):    PSNR={psnr_noisy:.2f} dB, SSIM={ssim_noisy:.4f}\n",
    "PN2V (MMSE):         PSNR={psnr_mmse:.2f} dB, SSIM={ssim_mmse:.4f}\n",
    "Supervisor Benchmark: PSNR=28.48 dB, SSIM=0.73\n",
    "{'-'*50}\n",
    "PSNR improvement: +{psnr_mmse - psnr_noisy:.2f} dB\n",
    "\"\"\"\n",
    "\n",
    "with open(f'{MODELS_DIR}/RESULTS_SUMMARY.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"   ‚úÖ RESULTS_SUMMARY.txt\")\n",
    "print(f\"\\nüéâ All results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f249bff0",
   "metadata": {},
   "source": [
    "## üîÑ Section 10: (Optional) Push to GitHub\n",
    "\n",
    "If you want to save your changes back to GitHub, run the cells below.\n",
    "\n",
    "**First time setup:** You need a GitHub Personal Access Token:\n",
    "1. Go to GitHub ‚Üí Settings ‚Üí Developer settings ‚Üí Personal access tokens\n",
    "2. Generate new token (classic) with `repo` scope\n",
    "3. Copy the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure git (run once)\n",
    "%cd /content/PPN2V\n",
    "\n",
    "!git config user.email \"your-email@example.com\"  # <-- Change this!\n",
    "!git config user.name \"ZurvanAkarna\"             # <-- Change this!\n",
    "\n",
    "print(\"‚úÖ Git configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c553d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your token (run once per session)\n",
    "# Replace YOUR_TOKEN_HERE with your actual GitHub token\n",
    "\n",
    "GITHUB_TOKEN = \"YOUR_TOKEN_HERE\"  # <-- Paste your token here!\n",
    "\n",
    "!git remote set-url origin https://{GITHUB_TOKEN}@github.com/ZurvanAkarna/PPN2V.git\n",
    "\n",
    "print(\"‚úÖ GitHub token configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what changed\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a571e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and push\n",
    "!git add -A\n",
    "!git commit -m \"Update from Colab: training results\"\n",
    "!git push origin main\n",
    "\n",
    "print(\"\\n‚úÖ Changes pushed to GitHub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f48a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Done!\n",
    "\n",
    "**Your results are saved to:**\n",
    "- Google Drive: `MyDrive/ppn2v_models/DATASET_01/`\n",
    "- GitHub: (if you ran Section 10)\n",
    "\n",
    "**Key files:**\n",
    "- `dataset01_denoised_mmse.tif` - Main denoised result\n",
    "- `dataset01_uncertainty_map.tif` - Uncertainty map\n",
    "- `RESULTS_SUMMARY.txt` - Metrics\n",
    "- `final_results.png` - Visualization\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
